---
title: 第一次使用Linux远程开发
date: 2025-02-12 12:00:00 +0800
categories: [笔记, 编程]
tags: [笔记, 编程, 深度学习, 远程开发, Linux, CUDA]
description: 事情要从大半夜11点收到老板的消息开始说起...
math: true
---

大半夜11点收到老板消息，有个紧急任务要给我做，项目的具体内容保密不能公开，大致情况就是深度学习那些内容。

看了一眼需求，很经典的resnet50的backbone，本地的电脑自然是带不动（我自己的电脑用的3060的卡），因此也是用上Linux服务器了。

Linux的部分我只是在本科自学Java那会的时候，拿CentOS稍微看过一点，但是当时也没怎么用，所以这次用说是从零开始也不为过了。

本则笔记大概记录一下使用过程中比较有意思的一些内容，后来把与mask2former相关一些的内容移动到了[这篇文档]({% post_url 2025-04-06-鏖战mask2former %})里面。

## Get Everything Started

如果要使用服务器的话，第一点肯定是要连接到服务器。

给的教程是CSDN的这篇[vscode连接远程服务器（傻瓜式教学）](https://blog.csdn.net/zhaxun/article/details/120568402)，用自己常用的VSCode环境做开发还是比较友好的，vim我自己用的实际上还不太熟。

在这个基础上，不算太难，相当于就是一个SSH的配置，跟自己提交Github大差不差。

## tmux

用VSCode跑训练进程的时候不可能整天守着+保持自己电脑开机，但是远端的服务器肯定是一直在跑的，这时候有个东西能监听session就好。

tmux我觉得是很符合直觉的一个工具，它就是干这个的。

使用方法参见[阮一峰的网络日志：Tmux 使用教程](https://www.ruanyifeng.com/blog/2019/10/tmux.html)。

## 谁更强？

~~没什么用的小知识增加了。~~

使用`nvidia-smi`居然会看不全GPU名字，看到了一行：

`|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |`

气笑了，解决方案是`nvidia-smi --query-gpu=name --format=csv,noheader`。

目前组里用的两张卡是NVIDIA GeForce RTX 4090和NVIDIA RTX A6000。乍一听前者显存24G，后者显存48G，感觉应该是后面那个厉害点，但发现后者跑模型明显速度不对劲。

找GPT要了个规格对比图。后起之秀，更耗电，核心更多，也难怪跑的更快了。

| 参数              | NVIDIA GeForce RTX 4090        | NVIDIA RTX A6000               |
| ----------------- | ------------------------------ | ------------------------------ |
| **架构**          | Ada Lovelace (AD102)           | Ampere (GA102)                 |
| **CUDA 核心数**   | 16384                          | 10752                          |
| **Tensor 核心数** | 512                            | 336                            |
| **显存容量**      | 24 GB GDDR6X                   | 48 GB GDDR6X                   |
| **显存带宽**      | 1008 GB/s                      | 700 GB/s                       |
| **功耗**          | 450W                           | 300W                           |
| **基础频率**      | 2235 MHz                       | 1395 MHz                       |
| **加速频率**      | 2520 MHz                       | 1695 MHz                       |
| **多精度性能**    | 高（支持 FP32、FP16、INT8 等） | 高（支持 FP32、FP16、TF32 等） |
| **发布日期**      | 2022年10月                     | 2020年12月                     |

另外，实测下来`IMS_PER_BATCH=2`只占16G左右的显存，但是GPU利用率已经干到70~80，往上加BATCH_SIZE虽然显存都用上了，但是训练速度却因为GPU满负荷反而会降低，这就很乐了。

## Hello, tex!

预计要投一篇ccf-b，学习了一下外文期刊的格式。

目前预订要投的这个会议给了一份 $$ \TeX $$ 模板。

因为学习过 $$ \LaTeX $$ 的原因所以相对比较简单，装了个TeXStudio+MikTeX最低环境，然后照着给的template改就完事了。

不得不说，虽然看着还是挺花的，但tex模板还是比Word方便很多，尤其是最后BibTeX的部分，特别省心。

~~希望毕设也能给个 $$ \TeX $$ 模板，不因为别的，就因为Word模板实在太恶心了，总要冷不丁坑你一下。~~