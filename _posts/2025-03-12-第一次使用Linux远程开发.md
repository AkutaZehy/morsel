---
title: 第一次使用Linux远程开发
date: 2025-02-12 12:00:00 +0800
categories: [笔记, 编程]
tags: [笔记, 编程, 深度学习, Linux, 远程开发]
description: 事情要从大半夜11点收到老板的消息开始说起...
---

大半夜11点收到老板消息，有个紧急任务要给我做，项目的具体内容保密不能公开，大致情况就是深度学习那些内容。

看了一眼需求，很经典的resnet50的backbone，本地的电脑自然是带不动（我自己的电脑用的3060的卡），因此也是用上Linux服务器了。

Linux的部分我只是在本科自学Java那会的时候，拿CentOS稍微看过一点，但是当时也没怎么用，所以这次用说是从零开始也不为过了。

本则笔记大概记录一下使用过程中比较有意思的一些内容。

## Get Everything Started

如果要使用服务器的话，第一点肯定是要连接到服务器。

给的教程是CSDN的这篇[vscode连接远程服务器（傻瓜式教学）](https://blog.csdn.net/zhaxun/article/details/120568402)，用自己常用的VSCode环境做开发还是比较友好的，vim我自己用的实际上还不太熟。

在这个基础上，不算太难，相当于就是一个SSH的配置，跟自己提交Github大差不差。

## 脑溢血的CUDA环境

看到服务器上的环境说真的眼前一黑，来自facebook的经典[Detectron2框架](https://github.com/facebookresearch/detectron2)。

本科的时候当时是做UNet和Mask R-CNN，后者就是用的这个框架，跑模型性能差时间长，还难改的一比，最后Down掉了用的UNet，对这个框架有心理阴影了。现在又要用这个，心里默念这个框架是真的阴魂不散。

当然这次不是用的完完全全的就这个框架就完了，实际上用的[Mask2Former](https://github.com/facebookresearch/Mask2Former)，这个框架是打底子了。

这里Former就是Transformer，QKV那一套，本科的时候也接触过，当时是做弱监督用，然而也是时间长效果差最后也没做下去了。

老实说这次能不能搞定这个项目心里真的没底，没辙硬着头皮做吧。

Detectron2这个框架对CUDA版本的要求相当严格，深度学习搭环境的老毛病了。

服务器上面有队友按开发文档（然而开发的库在今年年初就archived了），它是这么写的：

```bash
conda create --name mask2former python=3.8 -y
conda activate mask2former
conda install pytorch==1.9.0 torchvision==0.10.0 cudatoolkit=11.1 -c pytorch -c nvidia
pip install -U opencv-python

# under your working directory
git clone git@github.com:facebookresearch/detectron2.git
cd detectron2
pip install -e .
pip install git+https://github.com/cocodataset/panopticapi.git
pip install git+https://github.com/mcordts/cityscapesScripts.git

cd ..
git clone git@github.com:facebookresearch/Mask2Former.git
cd Mask2Former
pip install -r requirements.txt
cd mask2former/modeling/pixel_decoder/ops
sh make.sh
```

我自己尝试了一下本地部署，直接卡在`sh make.sh`这里，C我根本没学过，报一大堆啥玩意我也看不懂。后来才发现环境要求有一条是`Linux or macOS with Python ≥ 3.6`，我本地是Windows，所以直接放弃了。

服务器那边是Linux倒没问题，队友跟我说eval没问题，自己跑也确实没问题。

但是到了train和inference的时候就开始各种报错，还是C的，没办法丢给deepseek了，最后定位到：

`conda install pytorch==1.9.0 torchvision==0.10.0 cudatoolkit=11.1 -c pytorch -c nvidia`

这里的cudatoolkit是11.1，nvidia-smi显示服务器上的卡是CUDA 12.0，所以肯定是不兼容的。

此外，系统的CUDA_HOME的值是空的，需要手动设一下值，也算是复习vi了。

### 设置CUDA_HOME

有读写权限但是没sudo权限，不敢乱搞。

1. `vim ~/.bashrc`定位到环境变量。
2. 添加了形如以下内容到环境变量的末尾：
```
# ADD CUDA HOME
export CUDA_HOME=/usr/local/cuda
export PATH=$PATH:$CUDA_HOME/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_HOME/lib64
```
3. 保存退出（`esc`，`:wq`）
4. `source ~/.bashrc`使环境变量生效。
5. `nvcc -V`检查是否生效。

### 升级CUDA

没有卸载整个环境，用依赖管理尝试调整torch和cuda toolkit版本，最后确认cuda toolkit 11.7可用。

使用了`conda install pytorch==1.13.1 torchvision==0.14.1 cudatoolkit=11.7 -c pytorch -c nvidia`。

这个包有一说一下的是真的慢。

完成安装之后，重新走一遍流程，在`sh make.sh`前要手动`rm -rf build`清一下缓存。

## tmux

用VSCode跑训练进程的时候不可能整天守着+保持自己电脑开机，但是远端的服务器肯定是一直在跑的，这时候有个东西能监听session就好。

tmux我觉得是很符合直觉的一个工具，它就是干这个的。

使用方法参见[阮一峰的网络日志：Tmux 使用教程](https://www.ruanyifeng.com/blog/2019/10/tmux.html)。