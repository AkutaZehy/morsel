---
title: 开发疑难杂症汇总
date: 2025-08-10 12:00:00 +0800
categories:
  - 笔记
  - 编程
tags:
  - 笔记
  - 编程
  - 汇总
  - 深度学习
  - python
  - conda
  - linux
  - torch
description: It's time to funk the code.
---

尽管在 [conda你真的可以去死了]({% post_url _posts/2025-07-22-conda你真的可以去死了 %}) 一文里面已经对conda进行了详细的批判，然而，批判归批判，用还是得用，挺无奈的就。

> 本文还处于持续更新中。
{: .prompt-info }

> 由于是汇总，本文内容较长，请善用目录跳转。
{: .prompt-info }

## 前言

本文是对目前的工作状态（2024-？）所遇到的疑难杂症的大汇总，基本开发环境是在Linux（远程）下的Python开发，主要使用Conda的环境配置，因为涉及深度学习，所以也涉及到CUDA和Torch的配置。

根据遇到的问题，分为以下几类：

1. 基于Python，纯粹的Python特性问题（**内部库**），还有一些与其工具Pip、Conda之类的连携问题
2. 基于Python与深度学习，即Python深度学习常见**外部**库在配置上容易诱发冲突的问题与特性
3. 基于CUDA，主要为CUDA自身的特性和一些常见异常状况，包括Linux配置、与gcc的连携关系等
4. 基于深度学习库PyTorch/Torch的常见异常，包括和CUDA的连携异常等

## Python

### 参数列表的*和/是什么？

参见[Python官方文档：4.7.3 特殊参数](https://docs.python.org/zh-cn/3.8/tutorial/controlflow.html#special-parameters)。

一则实战参见[鏖战mask2former（一）]({% post_url 2025-04-12-鏖战mask2former（一） %})。

### ModuleNotFoundError

也算是Python复现代码时老生常谈的问题了，有时候明明目录结构清晰、文件就在那里，一运行却报`ModuleNotFoundError`，让人一头雾水。究其原因，通常逃不开两个核心问题：缺少`__init__.py`，或父路径未被纳入Python的模块搜索路径。

第一种情况常见于项目结构未按“包”规范组织。在 Python 3.3 之前，一个目录要被识别为包，必须包含`__init__.py`文件（哪怕为空）。没有它，Python就不会将其视为可导入的模块。虽然Python 3.3+引入了隐式命名空间包（[PEP 420](https://peps.python.org/pep-0420/)），允许在某些场景下省略该文件，但在绝大多数本地开发、相对导入、或打包分发的场景中，显式保留`__init__.py`仍是安全且推荐的做法。否则，`from mypackage import mymodule`就会因`mypackage`不被视为包而失败。

第二种情况则更隐蔽：Python根本“看不见”你的模块所在目录。即使目录结构正确、`__init__.py` 也齐全，若该目录的父级路径不在 `sys.path` 中，导入依然会失败。这在从非项目根目录运行脚本、或在Jupyter Notebook中跨目录导入时尤为常见。解决方法包括：
- 通过`PYTHONPATH`环境变量添加项目根路径；
- 在代码中动态 `sys.path.append(...)`（仅限开发调试）；
- 或更规范地，将项目设为可安装包并通过`pip install -e .`安装。

### Pip、Conda，包是如何管理的？

参见[Conda开发两则]({% post_url 2025-07-16-conda开发两则 %})

### 我的Conda更新了，但是没更新？

参见[Conda你真的可以去死了]({% post_url _posts/2025-07-22-conda你真的可以去死了 %})

### Future泛型错误（concurrent.futures）

> Future简介
{: .prompt-tip }

`concurrent.futures`模块是Python中用于实现异步执行的高级接口。它提供了一种编写多线程和多进程代码的简洁方式，而无需直接处理`threading`或`multiprocessing`模块的复杂细节。

它的核心是`Executor`抽象类和两个具体实现：

- `ThreadPoolExecutor`：使用线程池来异步执行任务。适用于I/O密集型操作（如网络请求、文件读写）。
- `ProcessPoolExecutor`：使用进程池来异步执行任务。适用于CPU密集型操作（如数学计算、图像处理），可以绕过GIL（全局解释器锁）充分利用多核CPU。

该模块的核心概念是`Future`对象。当你向`Executor`提交一个任务（使用`submit`方法）时，它会立即返回一个`Future`对象。这个`Future`对象是一个占位符，它代表着异步操作的“未来”结果。你可以通过这个对象来查询任务的状态（是否完成）、获取结果（会阻塞直到结果就绪）或取消任务。

在类型系统中，Future的理想用法是能够指定内部结果类型，例如`Future[int]`表示返回`int`的任务。

由Python 3.8诱发的问题：`TypeError: 'type' object is not subscriptable`。

考虑以下几种解法：

1. 升级到Python 3.9及以上，并使用泛型语法，这是最佳实践。
2. 在环境强依赖于Python 3.8的情况下，使用`typing`提供的泛型定义，如`typing.Future[None]`。
3. 我个人的HACK实践：在环境强依赖于Python 3.8，且`typing.Future[None]`似乎不太能解决问题的情况下，直接回避`Future`泛型，例如把原先的`List[Future[None]]`改为了`List`，这一做法通过牺牲类型注解的所有精确度实现了代码的兼容性。

> 以下是本问题详细的分析
{: .prompt-danger }

在Python 3.6及以前，原生Future不支持泛型语法，例如`Future[int]`，这会导致直接的、不可修复的`TypeError: 'type' object is not subscriptable`错误。

在Python 3.7，引入[PEP 560 – Core support for typing module and generic types](https://peps.python.org/pep-0560/)，为类定义新增`__class_getitem__`钩子方法，允许标准库和用户自定义类更方便地成为“泛型类”，然而大量内置类（如`Future`、`list`、`dict`）依旧不是泛型。

由于`Future`此时未实现`__class_getitem__`，因此无法使用泛型语法。

在Python 3.9，进一步引入[PEP 585 — Type Hinting Generics In Standard Collections](https://peps.python.org/pep-0585/)。让标准库的容器类和并发原语等原生支持泛型，避免依赖`typing.List`、`typing.Dict`这类“包装类”，`typing`中的别名（`List`、`Dict`、`Tuple`等）被标记为deprecated，并在Python 3.11中移除；标准库类（如`list`、`dict`、`tuple`、`concurrent.futures.Future`）都通过实现`__class_getitem__`，成为泛型类。

## 深度学习

### LabelMe（安装）

省流：最新的`labelme`别装有兼容性问题，`python==3.8`和`labelme==5.1.1`这个组合暂时确定是稳定的。

详细分析见下文：

[LabelMe的安装说明（Windows）]({% post_url 2025-03-17-labelme的安装说明（Windows） %})

### Pillow

`Pillow`是一个Python图像处理库，用于处理图像，例如读取、写入、显示、转换等。

`AttributeError: module ‘PIL.Image‘ has no attribute ‘ANTIALIAS‘`

在版本`Pillow>=10.0.0`，`PIL.Image.ANTIALIAS`被移除，取而代之的是`PIL.Image.LANCZOS`。因此要么降级`Pillow`，要么使用`PIL.Image.LANCZOS`作为替代。

### NumPy的分水岭

`NumPy`是一个Python库，用于处理多维数组。`NumPy`提供了大量的数学函数，用于对数组进行操作。

> Numpy 1.24
{: .prompt-tip }

`AttributeError: module 'numpy' has no attribute 'int'`

NumPy 1.20版本开始弃用，并在1.24版本中彻底移除了`np.int`、`np.float`等别名，以与Python内置类型保持一致。因此，要么降级NumPy，要么使用Python内置类型，通常来说，前者发生的概率较大，这是因为很多现在的深度学习开源代码都依赖于旧版的NumPy。

> Numpy 2.0
{: .prompt-tip }

Numpy 2.0是一个重大版本升级，改变了很多底层行为和API，对于那些在使用了旧版代码特性/语法糖来偷懒的代码，极容易出现不兼容的问题。

这种问题是极其显著而深远的，同时，也与诸如Pandas、Matplotlib、Scikit-learn、OpenCV等库的某些特定版本区间形成了强依赖绑定关系，强行适配NumPy 2.0的兼容成本过大（除了函数、函数签名对不上这类问题，依赖于旧版API的库都需要重新编译和开发，包括一系列C API），除非项目还处于起步阶段，否则更推荐不去升级到NumPy 2.0以上。

### pyproj

`pyproj`是Python中用于地理坐标系统（Coordinate Reference Systems, CRS）转换的核心库，广泛应用于遥感、地理信息系统（GIS）、以及涉及经纬度与投影坐标（如UTM）互转的深度学习任务中（例如卫星图像配准、轨迹建模、地图匹配等）。它底层封装了PROJ（原PROJ.4）库，负责在不同地理/投影坐标系之间高效、精确地转换坐标。

当你尝试将经纬度（lat-lon）批量转换为UTM坐标时，若使用如下旧式写法：

```python
pyproj.Proj(f"+proj=utm +zone={zone_number}{zone_letter}")  # 如 "+proj=utm +zone=50N"
```

在pyproj>=2.0（对应PROJ>=6）的环境中，会触发类似以下错误：

```
pyproj.exceptions.CRSError: Invalid projection: +proj=utm +zone=50N ...
```

或静默转换失败（坐标值异常），但不会报错，极具迷惑性。

这一变动源于PROJ库在6.0版本的重大重构，而pyproj 2.0+完全拥抱了新PROJ的规范：

- 旧版PROJ（<6.0）：允许在`+zone`参数中直接拼接半球字母（如50N），自动推断南北半球。
- 新版PROJ（>=6.0）：禁止在`+zone`中使用字母，要求zone仅为数字，并必须显式添加`+north`或`+south`来指定半球。

因此，`+zone=50N`被视为非法语法，导致CRS解析失败。

其中，一种可行的解法如下（兼容pyproj 2.x+）

```python
import utm
from pyproj import Proj

lat, lon = lats[0], lons[0]
zone_number = utm.latlon_to_zone_number(lat, lon)
zone_letter = utm.latitude_to_zone_letter(lat)

hemisphere = "+north" if zone_letter >= 'N' else "+south"
proj_dst = Proj(f"+proj=utm +zone={zone_number} {hemisphere}")
```

> 注意：`{hemisphere}` 前有空格，且为独立参数（`+north` 而非 `north`）。

更现代的最佳实践：避免直接拼接PROJ字符串，改用EPSG代码或CRS对象，让pyproj自动处理半球逻辑：

```python
from pyproj import Transformer
import utm

lat, lon = lats[0], lons[0]
zone_number = utm.latlon_to_zone_number(lat, lon)
is_north = lat >= 0

# 构造 EPSG 代码：北半球为 326XX，南半球为 327XX
epsg = 32600 + zone_number if is_north else 32700 + zone_number

transformer = Transformer.from_crs("EPSG:4326", f"EPSG:{epsg}", always_xy=True)
easts, norths = transformer.transform(lons, lats)
```

此方法：
- 无需手动判断半球；
- 使用标准EPSG编码，可读性强；
- 完全兼容新旧pyproj版本；
- 支持`always_xy=True`保证lon/lat顺序一致（避免经典XY顺序陷阱）。

## CUDA

### 单独指定一张卡来训练

参见[迎击mask2former]({% post_url 2025-04-06-迎击mask2former %})

### 找不到对应CUDA工具

例如，`/usr/bin/ld: cannot find -lxxx`，因为找不到工具而无法完成一个带有gcc编译的Python库安装。其中，xxx为工具名，例如`/usr/bin/ld: cannot find -lhdf5`表明gcc没有找到`libhdf5.so`这个库。

该问题与以下几个关键环境变量有关：

- `CUDA_HOME`：该环境变量通常指向CUDA的安装目录，例如`/usr/local/cuda`，该环境变量在安装CUDA时会被自动添加到环境变量中。其中，`/usr/local/cuda`是默认CUDA安装目录的symbolic link，指向实际的CUDA安装目录，例如`/usr/local/cuda-11.7`。
- `PATH`：该环境变量通常包含CUDA的bin目录，例如`/usr/local/cuda/bin`，该环境变量在安装CUDA时会被自动添加到环境变量中。
- `LIBRARY_PATH`：该环境变量通常包含CUDA的lib目录，例如`/usr/local/cuda/lib64`，该环境变量在安装CUDA时会被自动添加到环境变量中。
- `LD_LIBRARY_PATH`：该环境变量通常包含CUDA的lib目录，例如`/usr/local/cuda/lib64`，该环境变量在安装CUDA时会被自动添加到环境变量中。与`LIBRARY_PATH`不同的是，`LIBRARY_PATH`描述了**编译时**链接库的路径（即gcc编译时使用的库），而`LD_LIBRARY_PATH`描述了**运行时**链接库的路径（即运行时使用的库）。

第一种解决方案参见下文，这种做法在单机只有一个CUDA环境时比较方便。

[迎击mask2former]({% post_url 2025-04-06-迎击mask2former %})

在多CUDA环境中，通常需要用`export`方法来指定当前环境下的关键环境变量（如tmux线程）。

> 给出以下一个案例。
{: .prompt-tip }

首先，明确gcc编译需求的CUDA版本为11.3。

通过`ls /usr/local/`，可以看到`cuda`、`cuda-11.3`、`cuda-11.7`三个目录。

通过`nvcc --version`，可以看到当前CUDA版本为11.7，表明`cuda`是一个symbolic link，指向`cuda-11.7`。

接下来，需要检查`CUDA_HOME`、`PATH`、`LIBRARY_PATH`、`LD_LIBRARY_PATH`四个环境变量。通常来说，这些环境变量或多或少都会出现问题，例如`CUDA_HOME`有时会为空，`LD_LIBRARY_PATH`仅包括当前anaconda的env而并不包含CUDA的lib目录等。

接下来，逐个检查并设置环境变量。对于为空的环境变量，使用类似`export CUDA_HOME=/usr/local/cuda-11.3`的命令进行设置；对于非空的变量，使用类似`export PATH=$PATH:/usr/local/cuda-11.3/bin`的命令进行环境的追加。

通常来说，再次进行编译即可通过。

> 此外，还有一些非常规的特例，也一并记录下来。
{: .prompt-warning }

tiny-cuda-nn：这是一个轻量级的用于CUDA加速的Python库，已知的在安装过程中会出现的问题为`ld: cannot find -lcuda`。该问题被汇报于[Issue 183](https://github.com/NVlabs/tiny-cuda-nn/issues/183)。

事实上，此处丢失的文件`libcuda.so`并不在常规的`/usr/local/cuda/lib64`目录下，而是在`/usr/local/cuda/lib64/stubs`这个路径，因此对应地，需要额外添加`export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64/stubs`，问题得以解决。

## Torch / PyTorch

### Jupyter里面多线程卡住了？

假设你兴高采烈地调了类似下面的代码：

```python
from torch.utils.data import DataLoader

loader = DataLoader(
    dataset, 
    batch_size=32,
    num_workers=4, # 主要是这一行
    pin_memory=True,
    shuffle=True
)
```

观察到的现象：
- 程序启动后没有任何输出，或者打印了极少量信息后完全停止
- 控制台光标停止闪烁，程序看似运行中但实际上已停滞
- 使用`nvidia-smi`或类似方案查看发现GPU利用率始终为0%或不太高
- CPU使用率可能很高，但训练进度毫无进展
- 程序不会崩溃，也没有抛出任何错误信息，就是永远卡住，如果使用信号强行终止，大概率会发现程序没有进入第一个batch

最简单粗暴的解决方案：把`num_workers`设置为0，这也就意味着`DataLoader`不会使用多线程，而是直接在主线程中加载数据。

> 那么，这是怎么回事呢？
{: .prompt-danger }

首先，`DataLoader`的工作机制：当`num_workers>0`时，PyTorch会通过`multiprocessing`在后台启动多个worker进程来并行加载数据。这些worker使用队列把数据传回主进程。

在Linux上，Python默认的进程启动方式是`fork`。`fork`的工作方式是：它会复制父进程的内存空间。如果主进程在创建`DataLoader`之前已经创建了任何锁、文件描述符、或初始化了特定的全局状态（如CUDA驱动），这些状态会被原样复制到子进程中。但对于子进程来说，它并不知道这些资源已经被锁定或占用，当它尝试使用这些资源时，就会因为资源被父进程占用而陷入无限等待，最终导致死锁。

PyTorch 的官方推荐写法如下，即强制使用`spawn`模式启动子进程。

```python
if __name__ == "__main__":
    mp.set_start_method("spawn", force=True)
    ...
```

在Jupyter Notebook或IPython环境中，情况更加复杂。这些环境本身就是一个长期运行的父进程，代码不是在一个标准的`__main__`模块里运行，而是被包装进交互式解释器的环境。这会导致`spawn`模式无法正常工作（子进程要重新导入`__main__`，但Jupyter环境下没有标准的`__main__`文件）。

此外，Jupyter cell里的函数、类在worker里序列化传递时，依赖pickle。但cell定义的对象没有固定的模块名，pickle/unpickle亦会失败或阻塞。

除了`num_workers=0`这一粗暴的解决方案外，利用Jupyter Notebook调用多线程的实践是：把`Dataset`、模型等定义写在`.py`文件中再导入。

由于Jupyter Notebook本身也只是交互式的Python交互式计算环境，不太适用于多线程等复杂环境，因此，最佳实践是：

> 把代码放在`.py`文件中，使用python命令来运行，不要在Jupyter Notebook中运行。
